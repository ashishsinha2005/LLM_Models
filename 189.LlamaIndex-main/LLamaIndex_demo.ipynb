{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGrMBlXi2ODm"
      },
      "source": [
        "**1. Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKRsfHXQxelS",
        "outputId": "d6c6abfc-c673-47f8-9212-2ef5da33a2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install pypdf\n",
        "!pip install docx2txt\n",
        "!pip install transformer\n",
        "!pip install google-generativeai\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdMWPvLJ4q9F",
        "outputId": "7da40d10-5435-496a-b332-a1ce48544fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-palm in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-palm) (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-palm) (0.12.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (2.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (10.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (4.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.23.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (4.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (0.14.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (3.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (24.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-palm) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-palm) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-palm # Install the necessary package for PaLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWtLs4pj2xMu"
      },
      "source": [
        "**2. Load the necessary libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EKs0PAHv241U"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.llms.palm import PaLM\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvb9q9Cx46G8"
      },
      "source": [
        "**3. Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvptE8eP3VmS",
        "outputId": "ace7a920-6c49-4a8c-8fba-4589ff91a164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VX5IPfPT49GM"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader('data').load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl0qTJ3R5mMO",
        "outputId": "d6f22072-f4b6-4f0f-fa7f-8270c23070db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id_='b1f375ab-4860-4b2b-a435-7f87e90665b6', embedding=None, metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Introduction to Generative AI\\n\\nGenerative AI (Gen AI)\\n\\nGenerative AI is a type of artificial intelligence that can create new content, like writing, images, music, or even code, instead of just recognizing patterns or making predictions. It learns from a lot of data and uses that knowledge to produce something new and original, which can look or sound like the data it was trained on. \\n\\n\\n\\nHow Gen AI is differing from ML, DL, NLP and LLM?\\n\\n\\n\\n\\n\\nLLM (Large Language Model)\\n\\nA Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human language. It is built using a neural network that is trained on massive amounts of text data, allowing it to perform a wide variety of language-related tasks, such as answering questions, writing essays, translating languages, summarizing information, and even generating creative content like stories or poems.\\n\\nComparison of LLM and Gen AI:\\n\\nAspect\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nLarge Language Models (LLMs)\\n\\n\\n\\nDefinition\\n\\n\\n\\n\\n\\nAI models that can create new content, such as text, images, audio, or video\\n\\n\\n\\n\\n\\n\\n\\nA specific type of Gen AI focused on understanding and generating text\\n\\nFocus\\n\\n\\n\\n\\n\\nCan generate various forms of content (text, images, audio, video, etc.)\\n\\n\\n\\n\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n- DALL·E (image generation) \\n- GANs (image/video generation) \\n- Jukebox (music generation)\\n\\n\\n\\n\\n\\n\\n\\n- GPT-3, GPT-4 (text generation) \\n- BERT (text understanding)\\n\\nOutput Types\\n\\n\\n\\n\\n\\n- Text \\n- Images \\n- Audio \\n- Video\\n\\n\\n\\n\\n\\n- Text only\\n\\n\\n\\nPurpose\\n\\n\\n\\n\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\n\\n\\n\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\n\\n\\nKey Techniques\\n\\n\\n\\n\\n\\nUses various models like GANs, VAEs, Transformers\\n\\n\\n\\n\\n\\n\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\n\\n\\n\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\n\\n\\n\\n\\n\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n\\n\\n\\n\\n- Image synthesis \\n- Music composition \\n- Video generation\\n\\n\\n\\n\\n\\n\\n\\n- Chatbots \\n- Text generation \\n- Document summarization\\n\\nSubset Relationship\\n\\n\\n\\n\\n\\nBroad category, includes LLMs as a subset\\n\\n\\n\\n\\n\\nSubset of Generative AI, specifically dealing with text\\n\\n\\n\\n\\n\\nTraditional Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) versus Generative AI (Gen AI):\\n\\n\\n\\nAspect\\n\\n\\n\\nTraditional ML/DL/NLP\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nDefinition\\n\\n\\n\\nTraditional approaches for training models to recognize patterns and make predictions based on existing data.\\n\\n\\n\\nAI models that generate new content (text, images, audio, video, etc.) from learned patterns.\\n\\n\\n\\nFocus\\n\\n\\n\\nFocuses on tasks like classification, prediction, and pattern recognition.\\n\\n\\n\\nFocuses on creating new data, such as generating realistic images, writing text, composing music, etc.\\n\\n\\n\\nExamples\\n\\n\\n\\n- ML: Linear Regression, Decision Trees \\n- DL: CNNs, RNNs \\n- NLP: Named Entity Recognition (NER), Machine Translation\\n\\n\\n\\n- DALL·E (image generation) \\n- GPT-3/GPT-4 (text generation) \\n- GANs (image/video generation)\\n\\n\\n\\nOutput Types\\n\\n\\n\\nPredictions or classifications (e.g., spam detection, image recognition, text translation).\\n\\n\\n\\nNew, creative outputs like text, images, audio, or video.\\n\\n\\n\\nData Dependency\\n\\n\\n\\nRequires structured, labeled data for training and typically focuses on pre-defined outputs.\\n\\n\\n\\nCan work with both structured and unstructured data to create novel outputs that resemble the training data.\\n\\n\\n\\nPurpose\\n\\n\\n\\nTo make predictions, classifications, or decisions based on input data.\\n\\n\\n\\nTo generate new content and simulate creative processes similar to human creativity.\\n\\n\\n\\nTraining Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior\\n\\n\\n\\nRecognizes patterns and makes decisions based on those patterns (e.g., \"What is this image?\").\\n\\n\\n\\nGenerates new data by learning from patterns (e.g., \"Create an image based on this text prompt\").\\n\\n\\n\\nExample Use Cases\\n\\n\\n\\n- Fraud detection in banking \\n- Predicting house prices \\n- Recognizing objects in images \\n- Translating languages\\n\\n\\n\\n- Text generation for writing assistance \\n- Creating art or images \\n- Generating music or audio \\n- Video creation based on descriptions\\n\\n\\n\\nUser Interaction\\n\\n\\n\\nUsers typically input data and get predictions or classifications.\\n\\n\\n\\nUsers provide prompts or partial input (e.g., text description), and the model generates new content.\\n\\n\\n\\nSubset Relationship\\n\\n\\n\\nTraditional ML/DL/NLP are broader in their focus on structured prediction tasks.\\n\\n\\n\\nGen AI is a subset of AI that specializes in creating new, creative outputs.\\n\\n\\n\\n\\n\\n\\n\\nMilestone in LLM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAspect\\n\\nGen AI\\n\\nLLM\\n\\nDefinition\\n\\nAI Model that can create new content such as text, images, audio, or video.\\n\\nA specific type of Gen AI focused on understanding and generating text.\\n\\nFocus\\n\\nCan generate various forms of context (text, images, audio, video, etc.)\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing.\\n\\nExamples\\n\\n-DALL·E (image generation)\\n\\n-GANs (image/video generation)\\n\\n-Jukebox (music generation)\\n\\n-GPT-3, GPT-4 (text generation)\\n\\n-BERT (text understanding)\\n\\nOutput Types\\n\\n- Text\\n\\n- Images\\n\\n- Audio\\n\\n- Video\\n\\nText only\\n\\nPurpose\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\nKey Techniques\\n\\nUses various models like GANs, VAEs, Transformers\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n-Image synthesis \\n\\n-Music composition \\n\\n-Video generation\\n\\n- Chatbots \\n\\n-Text generation \\n\\n-Document summarization\\n\\nSubset Relationship\\n\\nBroad category, includes LLMs as a subset\\n\\nSubset of Generative AI, specifically dealing with text', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'),\n",
              " Document(id_='64911f41-cafb-4b9c-a9d6-f6e4831f1839', embedding=None, metadata={'file_name': '2. End to End Pipeline of Generative AI.docx', 'file_path': '/content/data/2. End to End Pipeline of Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 169015, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='End to End Pipeline of Generative AI\\n\\nData Acquisition\\n\\nData Preparation\\n\\nFeature Engineering\\n\\nModeling\\n\\nEvaluation\\n\\nDeployment\\n\\nMonitoring and Model updating\\n\\n\\n\\n\\n1. Data Acquisition\\n\\nThe first step is to gather relevant data for training. Data can come from various sources:\\n\\nAvailable Data: Structured files like CSV, text, PDF, DOCX, and XLSX formats.\\n\\nOther Data: Collected from APIs, databases, web scraping, or the internet.\\n\\nNo Data: If no data is available, it can be generated using LLMs (Large Language Models) like OpenAI’s GPT. For instance, by prompting models to generate sentences.\\n\\nData Augmentation:\\n\\nWhen the data volume is insufficient, augmentation techniques are applied to increase the dataset size artificially:\\n\\nSynonym Replacement: Substituting words with their synonyms.\\n\\nE.g., \"I am an AI Engineer\" → \"I am a Data Scientist.\"\\n\\nBigram Flip: Reordering phrases.\\n\\nE.g., \"I am Malavika\" → \"Malavika is my name.\"\\n\\nBack Translation: Translating a sentence to another language and back to the original.\\n\\nE.g., \"Data augmentation is the process of artificially generating new data\" translated to another language and back to English might become, \"Data mining is the process of routinely generating new data.\"\\n\\nAdding Noise:\\n\\nAdditional Data/Noise: Adding extra information or slight variations to existing sentences to create variations.\\n\\nE.g., \"I am an AI engineer. I love this job.\" → \"I love my job as an AI engineer.\"\\n\\n2. Data Preparation/Preprocessing\\n\\nThis stage involves cleaning and preparing data for model input:\\n\\nBasic Preprocessing:\\n\\nTokenization: Splitting text into smaller units like words or sentences.\\n\\nWord Tokenization: \"My name is Malavika\" → [\\'My\\', \\'name\\', \\'is\\', \\'Malavika\\']\\n\\nSentence Tokenization: \"My name is Malavika. I am an AI engineer.\" → [\\'My name is Malavika\\', \\'I am an AI engineer\\']\\n\\nStemming: Reducing words to their base form (root).\\n\\nE.g., \"play, played, playing\" → \"play\"\\n\\nLemmatization: A more advanced version of stemming that returns readable root forms.\\n\\nPunctuation Removal: Removing unnecessary punctuation marks (e.g., /, ?).\\n\\nLowercase Conversion: Converting text to lowercase to maintain uniformity.\\n\\nLanguage Detection: Identifying the language of the text.\\n\\nAdvanced Preprocessing:\\n\\nPart-of-Speech (POS) Tagging: Labeling words based on their grammatical roles.\\n\\n\\n\\nParsing Trees: Analyzing the grammatical structure of sentences.\\n\\n\\n\\nCoreference Resolution: Identifying which words refer to the same entities (e.g., resolving pronouns like \"he\" or \"it\").\\n\\n\\n\\n\\n\\n3. Feature Engineering\\n\\nTransforming raw text into numerical representations suitable for machine learning models.\\n\\nTF-IDF Vector: Measures word importance relative to a document and across a corpus.\\n\\nCount Vector: Counts the occurrences of words.\\n\\nHashing Vector: Uses hash functions to convert text to numerical representations.\\n\\nBag of Words: Represents text as a collection of words without considering order.\\n\\nOne-Hot Encoding: Represents individual words as binary vectors.\\n\\nTransformer Models: Advanced deep learning models like BERT or GPT to convert text into dense vectors.\\n\\nWord2Vec: Converts words into dense numerical vectors that capture semantic meanings.\\n\\n4. Modeling\\n\\nYou can either use open-source or paid models depending on the resources available.\\n\\nOpen-source LLM: These require infrastructure (CPU/GPU, memory) but can be run locally.\\n\\nPaid LLM (e.g., OpenAI): No infrastructure needed, just API integration.\\n\\n5. Evaluation\\n\\nEvaluation involves two aspects:\\n\\nIntrinsic Evaluation: Metrics evaluated by the generative AI engineer (e.g., perplexity, BLEU score, etc.).\\n\\nExtrinsic Evaluation: Feedback collected from users in real-world deployment.\\n\\n6. Deployment\\n\\nThis phase involves deploying the model to production. It requires setting up systems for continuous monitoring and periodic updates:\\n\\nMonitoring: Track the model\\'s performance, ensuring it meets desired metrics and outcomes.\\n\\nRetraining: Periodically retrain the model with new data or when performance degrades.\\n\\n\\n\\nCommon Terms:\\n\\nCorpus: The entire collection of sentences or texts used.\\n\\nVocabulary: Unique words present in the corpus.\\n\\nDocuments: Individual files (e.g., DOCX, PDF) containing text.\\n\\nWords: Single units of meaning arranged in order to create text.\\n\\nThis pipeline provides an end-to-end process for building generative AI systems, from gathering data to deploying the model and maintaining its performance.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pjzJcTE5oDE",
        "outputId": "2e2e766f-36d1-4386-a897-c0d9a193b7dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(id_='b1f375ab-4860-4b2b-a435-7f87e90665b6', embedding=None, metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Introduction to Generative AI\\n\\nGenerative AI (Gen AI)\\n\\nGenerative AI is a type of artificial intelligence that can create new content, like writing, images, music, or even code, instead of just recognizing patterns or making predictions. It learns from a lot of data and uses that knowledge to produce something new and original, which can look or sound like the data it was trained on. \\n\\n\\n\\nHow Gen AI is differing from ML, DL, NLP and LLM?\\n\\n\\n\\n\\n\\nLLM (Large Language Model)\\n\\nA Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human language. It is built using a neural network that is trained on massive amounts of text data, allowing it to perform a wide variety of language-related tasks, such as answering questions, writing essays, translating languages, summarizing information, and even generating creative content like stories or poems.\\n\\nComparison of LLM and Gen AI:\\n\\nAspect\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nLarge Language Models (LLMs)\\n\\n\\n\\nDefinition\\n\\n\\n\\n\\n\\nAI models that can create new content, such as text, images, audio, or video\\n\\n\\n\\n\\n\\n\\n\\nA specific type of Gen AI focused on understanding and generating text\\n\\nFocus\\n\\n\\n\\n\\n\\nCan generate various forms of content (text, images, audio, video, etc.)\\n\\n\\n\\n\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n- DALL·E (image generation) \\n- GANs (image/video generation) \\n- Jukebox (music generation)\\n\\n\\n\\n\\n\\n\\n\\n- GPT-3, GPT-4 (text generation) \\n- BERT (text understanding)\\n\\nOutput Types\\n\\n\\n\\n\\n\\n- Text \\n- Images \\n- Audio \\n- Video\\n\\n\\n\\n\\n\\n- Text only\\n\\n\\n\\nPurpose\\n\\n\\n\\n\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\n\\n\\n\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\n\\n\\nKey Techniques\\n\\n\\n\\n\\n\\nUses various models like GANs, VAEs, Transformers\\n\\n\\n\\n\\n\\n\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\n\\n\\n\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\n\\n\\n\\n\\n\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n\\n\\n\\n\\n- Image synthesis \\n- Music composition \\n- Video generation\\n\\n\\n\\n\\n\\n\\n\\n- Chatbots \\n- Text generation \\n- Document summarization\\n\\nSubset Relationship\\n\\n\\n\\n\\n\\nBroad category, includes LLMs as a subset\\n\\n\\n\\n\\n\\nSubset of Generative AI, specifically dealing with text\\n\\n\\n\\n\\n\\nTraditional Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) versus Generative AI (Gen AI):\\n\\n\\n\\nAspect\\n\\n\\n\\nTraditional ML/DL/NLP\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nDefinition\\n\\n\\n\\nTraditional approaches for training models to recognize patterns and make predictions based on existing data.\\n\\n\\n\\nAI models that generate new content (text, images, audio, video, etc.) from learned patterns.\\n\\n\\n\\nFocus\\n\\n\\n\\nFocuses on tasks like classification, prediction, and pattern recognition.\\n\\n\\n\\nFocuses on creating new data, such as generating realistic images, writing text, composing music, etc.\\n\\n\\n\\nExamples\\n\\n\\n\\n- ML: Linear Regression, Decision Trees \\n- DL: CNNs, RNNs \\n- NLP: Named Entity Recognition (NER), Machine Translation\\n\\n\\n\\n- DALL·E (image generation) \\n- GPT-3/GPT-4 (text generation) \\n- GANs (image/video generation)\\n\\n\\n\\nOutput Types\\n\\n\\n\\nPredictions or classifications (e.g., spam detection, image recognition, text translation).\\n\\n\\n\\nNew, creative outputs like text, images, audio, or video.\\n\\n\\n\\nData Dependency\\n\\n\\n\\nRequires structured, labeled data for training and typically focuses on pre-defined outputs.\\n\\n\\n\\nCan work with both structured and unstructured data to create novel outputs that resemble the training data.\\n\\n\\n\\nPurpose\\n\\n\\n\\nTo make predictions, classifications, or decisions based on input data.\\n\\n\\n\\nTo generate new content and simulate creative processes similar to human creativity.\\n\\n\\n\\nTraining Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior\\n\\n\\n\\nRecognizes patterns and makes decisions based on those patterns (e.g., \"What is this image?\").\\n\\n\\n\\nGenerates new data by learning from patterns (e.g., \"Create an image based on this text prompt\").\\n\\n\\n\\nExample Use Cases\\n\\n\\n\\n- Fraud detection in banking \\n- Predicting house prices \\n- Recognizing objects in images \\n- Translating languages\\n\\n\\n\\n- Text generation for writing assistance \\n- Creating art or images \\n- Generating music or audio \\n- Video creation based on descriptions\\n\\n\\n\\nUser Interaction\\n\\n\\n\\nUsers typically input data and get predictions or classifications.\\n\\n\\n\\nUsers provide prompts or partial input (e.g., text description), and the model generates new content.\\n\\n\\n\\nSubset Relationship\\n\\n\\n\\nTraditional ML/DL/NLP are broader in their focus on structured prediction tasks.\\n\\n\\n\\nGen AI is a subset of AI that specializes in creating new, creative outputs.\\n\\n\\n\\n\\n\\n\\n\\nMilestone in LLM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAspect\\n\\nGen AI\\n\\nLLM\\n\\nDefinition\\n\\nAI Model that can create new content such as text, images, audio, or video.\\n\\nA specific type of Gen AI focused on understanding and generating text.\\n\\nFocus\\n\\nCan generate various forms of context (text, images, audio, video, etc.)\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing.\\n\\nExamples\\n\\n-DALL·E (image generation)\\n\\n-GANs (image/video generation)\\n\\n-Jukebox (music generation)\\n\\n-GPT-3, GPT-4 (text generation)\\n\\n-BERT (text understanding)\\n\\nOutput Types\\n\\n- Text\\n\\n- Images\\n\\n- Audio\\n\\n- Video\\n\\nText only\\n\\nPurpose\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\nKey Techniques\\n\\nUses various models like GANs, VAEs, Transformers\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n-Image synthesis \\n\\n-Music composition \\n\\n-Video generation\\n\\n- Chatbots \\n\\n-Text generation \\n\\n-Document summarization\\n\\nSubset Relationship\\n\\nBroad category, includes LLMs as a subset\\n\\nSubset of Generative AI, specifically dealing with text', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "uPTmwqSX5tTn",
        "outputId": "be63776d-1720-42f5-de37-8274027358de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Introduction to Generative AI\\n\\nGenerative AI (Gen AI)\\n\\nGenerative AI is a type of artificial intelligence that can create new content, like writing, images, music, or even code, instead of just recognizing patterns or making predictions. It learns from a lot of data and uses that knowledge to produce something new and original, which can look or sound like the data it was trained on. \\n\\n\\n\\nHow Gen AI is differing from ML, DL, NLP and LLM?\\n\\n\\n\\n\\n\\nLLM (Large Language Model)\\n\\nA Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human language. It is built using a neural network that is trained on massive amounts of text data, allowing it to perform a wide variety of language-related tasks, such as answering questions, writing essays, translating languages, summarizing information, and even generating creative content like stories or poems.\\n\\nComparison of LLM and Gen AI:\\n\\nAspect\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nLarge Language Models (LLMs)\\n\\n\\n\\nDefinition\\n\\n\\n\\n\\n\\nAI models that can create new content, such as text, images, audio, or video\\n\\n\\n\\n\\n\\n\\n\\nA specific type of Gen AI focused on understanding and generating text\\n\\nFocus\\n\\n\\n\\n\\n\\nCan generate various forms of content (text, images, audio, video, etc.)\\n\\n\\n\\n\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n- DALL·E (image generation) \\n- GANs (image/video generation) \\n- Jukebox (music generation)\\n\\n\\n\\n\\n\\n\\n\\n- GPT-3, GPT-4 (text generation) \\n- BERT (text understanding)\\n\\nOutput Types\\n\\n\\n\\n\\n\\n- Text \\n- Images \\n- Audio \\n- Video\\n\\n\\n\\n\\n\\n- Text only\\n\\n\\n\\nPurpose\\n\\n\\n\\n\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\n\\n\\n\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\n\\n\\nKey Techniques\\n\\n\\n\\n\\n\\nUses various models like GANs, VAEs, Transformers\\n\\n\\n\\n\\n\\n\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\n\\n\\n\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\n\\n\\n\\n\\n\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n\\n\\n\\n\\n- Image synthesis \\n- Music composition \\n- Video generation\\n\\n\\n\\n\\n\\n\\n\\n- Chatbots \\n- Text generation \\n- Document summarization\\n\\nSubset Relationship\\n\\n\\n\\n\\n\\nBroad category, includes LLMs as a subset\\n\\n\\n\\n\\n\\nSubset of Generative AI, specifically dealing with text\\n\\n\\n\\n\\n\\nTraditional Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) versus Generative AI (Gen AI):\\n\\n\\n\\nAspect\\n\\n\\n\\nTraditional ML/DL/NLP\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nDefinition\\n\\n\\n\\nTraditional approaches for training models to recognize patterns and make predictions based on existing data.\\n\\n\\n\\nAI models that generate new content (text, images, audio, video, etc.) from learned patterns.\\n\\n\\n\\nFocus\\n\\n\\n\\nFocuses on tasks like classification, prediction, and pattern recognition.\\n\\n\\n\\nFocuses on creating new data, such as generating realistic images, writing text, composing music, etc.\\n\\n\\n\\nExamples\\n\\n\\n\\n- ML: Linear Regression, Decision Trees \\n- DL: CNNs, RNNs \\n- NLP: Named Entity Recognition (NER), Machine Translation\\n\\n\\n\\n- DALL·E (image generation) \\n- GPT-3/GPT-4 (text generation) \\n- GANs (image/video generation)\\n\\n\\n\\nOutput Types\\n\\n\\n\\nPredictions or classifications (e.g., spam detection, image recognition, text translation).\\n\\n\\n\\nNew, creative outputs like text, images, audio, or video.\\n\\n\\n\\nData Dependency\\n\\n\\n\\nRequires structured, labeled data for training and typically focuses on pre-defined outputs.\\n\\n\\n\\nCan work with both structured and unstructured data to create novel outputs that resemble the training data.\\n\\n\\n\\nPurpose\\n\\n\\n\\nTo make predictions, classifications, or decisions based on input data.\\n\\n\\n\\nTo generate new content and simulate creative processes similar to human creativity.\\n\\n\\n\\nTraining Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior\\n\\n\\n\\nRecognizes patterns and makes decisions based on those patterns (e.g., \"What is this image?\").\\n\\n\\n\\nGenerates new data by learning from patterns (e.g., \"Create an image based on this text prompt\").\\n\\n\\n\\nExample Use Cases\\n\\n\\n\\n- Fraud detection in banking \\n- Predicting house prices \\n- Recognizing objects in images \\n- Translating languages\\n\\n\\n\\n- Text generation for writing assistance \\n- Creating art or images \\n- Generating music or audio \\n- Video creation based on descriptions\\n\\n\\n\\nUser Interaction\\n\\n\\n\\nUsers typically input data and get predictions or classifications.\\n\\n\\n\\nUsers provide prompts or partial input (e.g., text description), and the model generates new content.\\n\\n\\n\\nSubset Relationship\\n\\n\\n\\nTraditional ML/DL/NLP are broader in their focus on structured prediction tasks.\\n\\n\\n\\nGen AI is a subset of AI that specializes in creating new, creative outputs.\\n\\n\\n\\n\\n\\n\\n\\nMilestone in LLM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAspect\\n\\nGen AI\\n\\nLLM\\n\\nDefinition\\n\\nAI Model that can create new content such as text, images, audio, or video.\\n\\nA specific type of Gen AI focused on understanding and generating text.\\n\\nFocus\\n\\nCan generate various forms of context (text, images, audio, video, etc.)\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing.\\n\\nExamples\\n\\n-DALL·E (image generation)\\n\\n-GANs (image/video generation)\\n\\n-Jukebox (music generation)\\n\\n-GPT-3, GPT-4 (text generation)\\n\\n-BERT (text understanding)\\n\\nOutput Types\\n\\n- Text\\n\\n- Images\\n\\n- Audio\\n\\n- Video\\n\\nText only\\n\\nPurpose\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\nKey Techniques\\n\\nUses various models like GANs, VAEs, Transformers\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n-Image synthesis \\n\\n-Music composition \\n\\n-Video generation\\n\\n- Chatbots \\n\\n-Text generation \\n\\n-Document summarization\\n\\nSubset Relationship\\n\\nBroad category, includes LLMs as a subset\\n\\nSubset of Generative AI, specifically dealing with text'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFG2f8qo52V8"
      },
      "source": [
        "**4. Split the Text into small chunks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ym_S5RA7Vs7",
        "outputId": "377ca0e0-2de3-4b71-8954-01cd3362a1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.26.5)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (0.12.5)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.10)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_l-TORn51Gw",
        "outputId": "a238b0e5-981f-4421-d84d-8c242b912e70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Initialize the embedding model\n",
        "embedding_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVaPRatK-z6n",
        "outputId": "48fb5ab5-3bc0-404a-e8a4-5e5f71c74121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.5)\n",
            "Requirement already satisfied: google-generativeai>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-gemini) (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-gemini) (0.12.5)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-gemini) (10.4.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.10)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.25.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.57.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.17.0)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai>=0.5.2->llama-index-llms-gemini) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (3.23.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (1.2.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-gemini) (24.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-gemini llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xqkKnTrEDS1"
      },
      "source": [
        "**5. LLM Model Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC1j5adsCSrQ",
        "outputId": "72942211-6bc3-4d38-9927-9c5d71b84424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5T49S06y7fEI"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY='****************'\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XZ9j9qYTDSJh"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "llm = Gemini(\n",
        "    model=\"models/gemini-1.5-pro\",\n",
        "    # api_key=\"some key\",  # uses GOOGLE_API_KEY env var by default\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DaxqLua776e4"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "# Configure the global settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embedding_model\n",
        "\n",
        "# Now you can proceed with creating your index without using ServiceContext\n",
        "# For example:\n",
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3vnsZ7JERNx"
      },
      "source": [
        "**6. Store the data index**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8WWrCQwQ8h4U"
      },
      "outputs": [],
      "source": [
        "index.storage_context.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wBOQNdCEWtx"
      },
      "source": [
        "**7. Create query**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-coTONIP8mrP"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HzaVRRTq8p3e",
        "outputId": "b333ba5d-114f-4f9d-8c85-b8e039272d16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Response(response='This document does not contain any information about \"llamaindex\". Therefore, I cannot answer your question.\\n', source_nodes=[NodeWithScore(node=TextNode(id_='fc34ac1b-ec88-4b34-9a0d-a4d1e7e2c0b6', embedding=None, metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b1f375ab-4860-4b2b-a435-7f87e90665b6', node_type='4', metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, hash='a78b8cec3becec9a89443af62fd53012ad1d9770740ef35789da80004cb9208c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0ece96bb-6113-4113-ac79-54a97441d40f', node_type='1', metadata={}, hash='f18962b5e8cbc2a400b1562f933286b6070a1c31416a9028de728e2564159720')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Introduction to Generative AI\\n\\nGenerative AI (Gen AI)\\n\\nGenerative AI is a type of artificial intelligence that can create new content, like writing, images, music, or even code, instead of just recognizing patterns or making predictions. It learns from a lot of data and uses that knowledge to produce something new and original, which can look or sound like the data it was trained on. \\n\\n\\n\\nHow Gen AI is differing from ML, DL, NLP and LLM?\\n\\n\\n\\n\\n\\nLLM (Large Language Model)\\n\\nA Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human language. It is built using a neural network that is trained on massive amounts of text data, allowing it to perform a wide variety of language-related tasks, such as answering questions, writing essays, translating languages, summarizing information, and even generating creative content like stories or poems.\\n\\nComparison of LLM and Gen AI:\\n\\nAspect\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nLarge Language Models (LLMs)\\n\\n\\n\\nDefinition\\n\\n\\n\\n\\n\\nAI models that can create new content, such as text, images, audio, or video\\n\\n\\n\\n\\n\\n\\n\\nA specific type of Gen AI focused on understanding and generating text\\n\\nFocus\\n\\n\\n\\n\\n\\nCan generate various forms of content (text, images, audio, video, etc.)\\n\\n\\n\\n\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n- DALL·E (image generation) \\n- GANs (image/video generation) \\n- Jukebox (music generation)\\n\\n\\n\\n\\n\\n\\n\\n- GPT-3, GPT-4 (text generation) \\n- BERT (text understanding)\\n\\nOutput Types\\n\\n\\n\\n\\n\\n- Text \\n- Images \\n- Audio \\n- Video\\n\\n\\n\\n\\n\\n- Text only\\n\\n\\n\\nPurpose\\n\\n\\n\\n\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\n\\n\\n\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\n\\n\\nKey Techniques\\n\\n\\n\\n\\n\\nUses various models like GANs, VAEs, Transformers\\n\\n\\n\\n\\n\\n\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\n\\n\\n\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\n\\n\\n\\n\\n\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n\\n\\n\\n\\n- Image synthesis \\n- Music composition \\n- Video generation\\n\\n\\n\\n\\n\\n\\n\\n- Chatbots \\n- Text generation \\n- Document summarization\\n\\nSubset Relationship\\n\\n\\n\\n\\n\\nBroad category, includes LLMs as a subset\\n\\n\\n\\n\\n\\nSubset of Generative AI, specifically dealing with text\\n\\n\\n\\n\\n\\nTraditional Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) versus Generative AI (Gen AI):\\n\\n\\n\\nAspect\\n\\n\\n\\nTraditional ML/DL/NLP\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nDefinition\\n\\n\\n\\nTraditional approaches for training models to recognize patterns and make predictions based on existing data.\\n\\n\\n\\nAI models that generate new content (text, images, audio, video, etc.) from learned patterns.\\n\\n\\n\\nFocus\\n\\n\\n\\nFocuses on tasks like classification, prediction, and pattern recognition.\\n\\n\\n\\nFocuses on creating new data, such as generating realistic images, writing text, composing music, etc.\\n\\n\\n\\nExamples\\n\\n\\n\\n- ML: Linear Regression, Decision Trees \\n- DL: CNNs, RNNs \\n- NLP: Named Entity Recognition (NER), Machine Translation\\n\\n\\n\\n- DALL·E (image generation) \\n- GPT-3/GPT-4 (text generation) \\n- GANs (image/video generation)\\n\\n\\n\\nOutput Types\\n\\n\\n\\nPredictions or classifications (e.g., spam detection, image recognition, text translation).\\n\\n\\n\\nNew, creative outputs like text, images, audio, or video.\\n\\n\\n\\nData Dependency\\n\\n\\n\\nRequires structured, labeled data for training and typically focuses on pre-defined outputs.\\n\\n\\n\\nCan work with both structured and unstructured data to create novel outputs that resemble the training data.\\n\\n\\n\\nPurpose\\n\\n\\n\\nTo make predictions, classifications, or decisions based on input data.\\n\\n\\n\\nTo generate new content and simulate creative processes similar to human creativity.\\n\\n\\n\\nTraining Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior', mimetype='text/plain', start_char_idx=0, end_char_idx=4618, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.24096175308243328), NodeWithScore(node=TextNode(id_='0ece96bb-6113-4113-ac79-54a97441d40f', embedding=None, metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b1f375ab-4860-4b2b-a435-7f87e90665b6', node_type='4', metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, hash='a78b8cec3becec9a89443af62fd53012ad1d9770740ef35789da80004cb9208c'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='fc34ac1b-ec88-4b34-9a0d-a4d1e7e2c0b6', node_type='1', metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, hash='466055a11d6306e26e6732d11bd3b4217eda6869164a4485c550282268a97204')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Training Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior\\n\\n\\n\\nRecognizes patterns and makes decisions based on those patterns (e.g., \"What is this image?\").\\n\\n\\n\\nGenerates new data by learning from patterns (e.g., \"Create an image based on this text prompt\").\\n\\n\\n\\nExample Use Cases\\n\\n\\n\\n- Fraud detection in banking \\n- Predicting house prices \\n- Recognizing objects in images \\n- Translating languages\\n\\n\\n\\n- Text generation for writing assistance \\n- Creating art or images \\n- Generating music or audio \\n- Video creation based on descriptions\\n\\n\\n\\nUser Interaction\\n\\n\\n\\nUsers typically input data and get predictions or classifications.\\n\\n\\n\\nUsers provide prompts or partial input (e.g., text description), and the model generates new content.\\n\\n\\n\\nSubset Relationship\\n\\n\\n\\nTraditional ML/DL/NLP are broader in their focus on structured prediction tasks.\\n\\n\\n\\nGen AI is a subset of AI that specializes in creating new, creative outputs.\\n\\n\\n\\n\\n\\n\\n\\nMilestone in LLM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAspect\\n\\nGen AI\\n\\nLLM\\n\\nDefinition\\n\\nAI Model that can create new content such as text, images, audio, or video.\\n\\nA specific type of Gen AI focused on understanding and generating text.\\n\\nFocus\\n\\nCan generate various forms of context (text, images, audio, video, etc.)\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing.\\n\\nExamples\\n\\n-DALL·E (image generation)\\n\\n-GANs (image/video generation)\\n\\n-Jukebox (music generation)\\n\\n-GPT-3, GPT-4 (text generation)\\n\\n-BERT (text understanding)\\n\\nOutput Types\\n\\n- Text\\n\\n- Images\\n\\n- Audio\\n\\n- Video\\n\\nText only\\n\\nPurpose\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\nKey Techniques\\n\\nUses various models like GANs, VAEs, Transformers\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n-Image synthesis \\n\\n-Music composition \\n\\n-Video generation\\n\\n- Chatbots \\n\\n-Text generation \\n\\n-Document summarization\\n\\nSubset Relationship\\n\\nBroad category, includes LLMs as a subset\\n\\nSubset of Generative AI, specifically dealing with text', mimetype='text/plain', start_char_idx=3690, end_char_idx=6748, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.12222825093114302)], metadata={'fc34ac1b-ec88-4b34-9a0d-a4d1e7e2c0b6': {'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, '0ece96bb-6113-4113-ac79-54a97441d40f': {'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = query_engine.query(\"What is llamaindex?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kThDzoa2EbMp"
      },
      "source": [
        "**8. Check in a understandable way**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "Afpg2Nov8rfy",
        "outputId": "6cc0ac21-830f-4645-a01a-a6b0b7b31361"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>This document does not contain any information about \"llamaindex\". Therefore, I cannot answer your question.\n",
              "</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5l-4PIEJDylR",
        "outputId": "a7079d99-4acb-42c9-9a44-7b05f89c6c38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Response(response='Generative AI (Gen AI) is a type of artificial intelligence that creates various kinds of new content, including text, images, music, and even code.  It learns patterns from input data and then uses this knowledge to generate original content that resembles the data it was trained on.\\n', source_nodes=[NodeWithScore(node=TextNode(id_='fc34ac1b-ec88-4b34-9a0d-a4d1e7e2c0b6', embedding=None, metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b1f375ab-4860-4b2b-a435-7f87e90665b6', node_type='4', metadata={'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, hash='a78b8cec3becec9a89443af62fd53012ad1d9770740ef35789da80004cb9208c'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='0ece96bb-6113-4113-ac79-54a97441d40f', node_type='1', metadata={}, hash='f18962b5e8cbc2a400b1562f933286b6070a1c31416a9028de728e2564159720')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Introduction to Generative AI\\n\\nGenerative AI (Gen AI)\\n\\nGenerative AI is a type of artificial intelligence that can create new content, like writing, images, music, or even code, instead of just recognizing patterns or making predictions. It learns from a lot of data and uses that knowledge to produce something new and original, which can look or sound like the data it was trained on. \\n\\n\\n\\nHow Gen AI is differing from ML, DL, NLP and LLM?\\n\\n\\n\\n\\n\\nLLM (Large Language Model)\\n\\nA Large Language Model (LLM) is a type of artificial intelligence model designed to understand and generate human language. It is built using a neural network that is trained on massive amounts of text data, allowing it to perform a wide variety of language-related tasks, such as answering questions, writing essays, translating languages, summarizing information, and even generating creative content like stories or poems.\\n\\nComparison of LLM and Gen AI:\\n\\nAspect\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nLarge Language Models (LLMs)\\n\\n\\n\\nDefinition\\n\\n\\n\\n\\n\\nAI models that can create new content, such as text, images, audio, or video\\n\\n\\n\\n\\n\\n\\n\\nA specific type of Gen AI focused on understanding and generating text\\n\\nFocus\\n\\n\\n\\n\\n\\nCan generate various forms of content (text, images, audio, video, etc.)\\n\\n\\n\\n\\n\\nPrimarily focuses on text-based tasks like writing, answering questions, or summarizing\\n\\n\\n\\nExamples\\n\\n\\n\\n\\n\\n- DALL·E (image generation) \\n- GANs (image/video generation) \\n- Jukebox (music generation)\\n\\n\\n\\n\\n\\n\\n\\n- GPT-3, GPT-4 (text generation) \\n- BERT (text understanding)\\n\\nOutput Types\\n\\n\\n\\n\\n\\n- Text \\n- Images \\n- Audio \\n- Video\\n\\n\\n\\n\\n\\n- Text only\\n\\n\\n\\nPurpose\\n\\n\\n\\n\\n\\nBroader purpose, used in creativity, design, entertainment, and more\\n\\n\\n\\n\\n\\nSpecialized in language-related tasks like chatting, translation, summarization\\n\\n\\n\\nKey Techniques\\n\\n\\n\\n\\n\\nUses various models like GANs, VAEs, Transformers\\n\\n\\n\\n\\n\\n\\n\\nPrimarily based on Transformer architecture\\n\\nDomain\\n\\n\\n\\n\\n\\nMulti-domain (art, design, text, music, etc.)\\n\\n\\n\\n\\n\\n\\n\\nFocused on natural language processing (NLP)\\n\\nExample Use Cases\\n\\n\\n\\n\\n\\n- Image synthesis \\n- Music composition \\n- Video generation\\n\\n\\n\\n\\n\\n\\n\\n- Chatbots \\n- Text generation \\n- Document summarization\\n\\nSubset Relationship\\n\\n\\n\\n\\n\\nBroad category, includes LLMs as a subset\\n\\n\\n\\n\\n\\nSubset of Generative AI, specifically dealing with text\\n\\n\\n\\n\\n\\nTraditional Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) versus Generative AI (Gen AI):\\n\\n\\n\\nAspect\\n\\n\\n\\nTraditional ML/DL/NLP\\n\\n\\n\\nGenerative AI (Gen AI)\\n\\n\\n\\nDefinition\\n\\n\\n\\nTraditional approaches for training models to recognize patterns and make predictions based on existing data.\\n\\n\\n\\nAI models that generate new content (text, images, audio, video, etc.) from learned patterns.\\n\\n\\n\\nFocus\\n\\n\\n\\nFocuses on tasks like classification, prediction, and pattern recognition.\\n\\n\\n\\nFocuses on creating new data, such as generating realistic images, writing text, composing music, etc.\\n\\n\\n\\nExamples\\n\\n\\n\\n- ML: Linear Regression, Decision Trees \\n- DL: CNNs, RNNs \\n- NLP: Named Entity Recognition (NER), Machine Translation\\n\\n\\n\\n- DALL·E (image generation) \\n- GPT-3/GPT-4 (text generation) \\n- GANs (image/video generation)\\n\\n\\n\\nOutput Types\\n\\n\\n\\nPredictions or classifications (e.g., spam detection, image recognition, text translation).\\n\\n\\n\\nNew, creative outputs like text, images, audio, or video.\\n\\n\\n\\nData Dependency\\n\\n\\n\\nRequires structured, labeled data for training and typically focuses on pre-defined outputs.\\n\\n\\n\\nCan work with both structured and unstructured data to create novel outputs that resemble the training data.\\n\\n\\n\\nPurpose\\n\\n\\n\\nTo make predictions, classifications, or decisions based on input data.\\n\\n\\n\\nTo generate new content and simulate creative processes similar to human creativity.\\n\\n\\n\\nTraining Data\\n\\n\\n\\nNeeds specific input-output pairs for supervised learning tasks.\\n\\n\\n\\nTrained on large datasets (e.g., text, images) to learn the patterns and then generate new data.\\n\\n\\n\\nComplexity\\n\\n\\n\\nTraditional ML is simpler (requires less data and computation); DL models (like CNNs and RNNs) need more data and are more complex.\\n\\n\\n\\nGenerally more complex due to larger models and more diverse outputs, often using advanced architectures like GANs or Transformers.\\n\\n\\n\\nApplication Domain\\n\\n\\n\\nUsed in tasks like fraud detection, stock market prediction, image classification, language translation.\\n\\n\\n\\nUsed in creative tasks like text writing, image creation, music composition, and video generation.\\n\\n\\n\\nArchitecture\\n\\n\\n\\n- ML: Decision Trees, SVMs, Logistic Regression \\n- DL: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs)\\n\\n\\n\\nGenerative models like Transformer-based LLMs (GPT), GANs, VAEs.\\n\\n\\n\\nModel Behavior', mimetype='text/plain', start_char_idx=0, end_char_idx=4618, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3335991476953869), NodeWithScore(node=TextNode(id_='1cf5a8ab-2958-445b-9465-9ea2936f185e', embedding=None, metadata={'file_name': '2. End to End Pipeline of Generative AI.docx', 'file_path': '/content/data/2. End to End Pipeline of Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 169015, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='64911f41-cafb-4b9c-a9d6-f6e4831f1839', node_type='4', metadata={'file_name': '2. End to End Pipeline of Generative AI.docx', 'file_path': '/content/data/2. End to End Pipeline of Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 169015, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, hash='16673467c8e2adec2d793f0fc0b531024c06d307420022642a37b544a6101caa')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='End to End Pipeline of Generative AI\\n\\nData Acquisition\\n\\nData Preparation\\n\\nFeature Engineering\\n\\nModeling\\n\\nEvaluation\\n\\nDeployment\\n\\nMonitoring and Model updating\\n\\n\\n\\n\\n1. Data Acquisition\\n\\nThe first step is to gather relevant data for training. Data can come from various sources:\\n\\nAvailable Data: Structured files like CSV, text, PDF, DOCX, and XLSX formats.\\n\\nOther Data: Collected from APIs, databases, web scraping, or the internet.\\n\\nNo Data: If no data is available, it can be generated using LLMs (Large Language Models) like OpenAI’s GPT. For instance, by prompting models to generate sentences.\\n\\nData Augmentation:\\n\\nWhen the data volume is insufficient, augmentation techniques are applied to increase the dataset size artificially:\\n\\nSynonym Replacement: Substituting words with their synonyms.\\n\\nE.g., \"I am an AI Engineer\" → \"I am a Data Scientist.\"\\n\\nBigram Flip: Reordering phrases.\\n\\nE.g., \"I am Malavika\" → \"Malavika is my name.\"\\n\\nBack Translation: Translating a sentence to another language and back to the original.\\n\\nE.g., \"Data augmentation is the process of artificially generating new data\" translated to another language and back to English might become, \"Data mining is the process of routinely generating new data.\"\\n\\nAdding Noise:\\n\\nAdditional Data/Noise: Adding extra information or slight variations to existing sentences to create variations.\\n\\nE.g., \"I am an AI engineer. I love this job.\" → \"I love my job as an AI engineer.\"\\n\\n2. Data Preparation/Preprocessing\\n\\nThis stage involves cleaning and preparing data for model input:\\n\\nBasic Preprocessing:\\n\\nTokenization: Splitting text into smaller units like words or sentences.\\n\\nWord Tokenization: \"My name is Malavika\" → [\\'My\\', \\'name\\', \\'is\\', \\'Malavika\\']\\n\\nSentence Tokenization: \"My name is Malavika. I am an AI engineer.\" → [\\'My name is Malavika\\', \\'I am an AI engineer\\']\\n\\nStemming: Reducing words to their base form (root).\\n\\nE.g., \"play, played, playing\" → \"play\"\\n\\nLemmatization: A more advanced version of stemming that returns readable root forms.\\n\\nPunctuation Removal: Removing unnecessary punctuation marks (e.g., /, ?).\\n\\nLowercase Conversion: Converting text to lowercase to maintain uniformity.\\n\\nLanguage Detection: Identifying the language of the text.\\n\\nAdvanced Preprocessing:\\n\\nPart-of-Speech (POS) Tagging: Labeling words based on their grammatical roles.\\n\\n\\n\\nParsing Trees: Analyzing the grammatical structure of sentences.\\n\\n\\n\\nCoreference Resolution: Identifying which words refer to the same entities (e.g., resolving pronouns like \"he\" or \"it\").\\n\\n\\n\\n\\n\\n3. Feature Engineering\\n\\nTransforming raw text into numerical representations suitable for machine learning models.\\n\\nTF-IDF Vector: Measures word importance relative to a document and across a corpus.\\n\\nCount Vector: Counts the occurrences of words.\\n\\nHashing Vector: Uses hash functions to convert text to numerical representations.\\n\\nBag of Words: Represents text as a collection of words without considering order.\\n\\nOne-Hot Encoding: Represents individual words as binary vectors.\\n\\nTransformer Models: Advanced deep learning models like BERT or GPT to convert text into dense vectors.\\n\\nWord2Vec: Converts words into dense numerical vectors that capture semantic meanings.\\n\\n4. Modeling\\n\\nYou can either use open-source or paid models depending on the resources available.\\n\\nOpen-source LLM: These require infrastructure (CPU/GPU, memory) but can be run locally.\\n\\nPaid LLM (e.g., OpenAI): No infrastructure needed, just API integration.\\n\\n5. Evaluation\\n\\nEvaluation involves two aspects:\\n\\nIntrinsic Evaluation: Metrics evaluated by the generative AI engineer (e.g., perplexity, BLEU score, etc.).\\n\\nExtrinsic Evaluation: Feedback collected from users in real-world deployment.\\n\\n6. Deployment\\n\\nThis phase involves deploying the model to production. It requires setting up systems for continuous monitoring and periodic updates:\\n\\nMonitoring: Track the model\\'s performance, ensuring it meets desired metrics and outcomes.\\n\\nRetraining: Periodically retrain the model with new data or when performance degrades.\\n\\n\\n\\nCommon Terms:\\n\\nCorpus: The entire collection of sentences or texts used.\\n\\nVocabulary: Unique words present in the corpus.\\n\\nDocuments: Individual files (e.g., DOCX, PDF) containing text.\\n\\nWords: Single units of meaning arranged in order to create text.\\n\\nThis pipeline provides an end-to-end process for building generative AI systems, from gathering data to deploying the model and maintaining its performance.', mimetype='text/plain', start_char_idx=0, end_char_idx=4435, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.23567083083003218)], metadata={'fc34ac1b-ec88-4b34-9a0d-a4d1e7e2c0b6': {'file_name': '1. Introduction to Generative AI.docx', 'file_path': '/content/data/1. Introduction to Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 431129, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}, '1cf5a8ab-2958-445b-9465-9ea2936f185e': {'file_name': '2. End to End Pipeline of Generative AI.docx', 'file_path': '/content/data/2. End to End Pipeline of Generative AI.docx', 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 169015, 'creation_date': '2024-12-14', 'last_modified_date': '2024-12-14'}})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = query_engine.query(\"What is Genai?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "YGIGjMrHD5xi",
        "outputId": "06904fc0-603a-4b80-fe5c-990c2ecf74e2"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>Generative AI (Gen AI) is a type of artificial intelligence that creates various kinds of new content, including text, images, music, and even code.  It learns patterns from input data and then uses this knowledge to generate original content that resembles the data it was trained on.\n",
              "</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NoIPcGmD7dZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
